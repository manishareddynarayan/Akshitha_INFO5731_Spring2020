{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Copy_of_Copy_of_Copy_of_Copy_of_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshithamaddi/Akshitha_INFO5731_Spring2020/blob/master/Copy_of_Copy_of_Copy_of_Copy_of_Copy_of_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_G3fm790SEc",
        "colab_type": "code",
        "outputId": "b0c75ca5-4984-40c4-fd6b-8b17016d0fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qFQrHji0E3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "# Select all the files in your directory\n",
        "directory = r'/content/drive/My Drive/sigir_data'\n",
        "files = glob.glob(directory + \"/*.csv\")\n",
        "df1 = pd.concat([pd.read_csv(fp,skipinitialspace=True,encoding = \"ISO-8859-1\").assign(New=os.path.basename(fp)) for fp in files])\n",
        "df1['article_no'] = df1['article_id'].str.replace('https://doi.org/','')\n",
        "df1.to_csv('output.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owyp47VWri1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"output.csv\") \n",
        "df1 = data[pd.notnull(data['article_id'])]\n",
        "df1.to_csv('articleoutput.csv')\n",
        "#reading the csvfile\n",
        "data = pd.read_csv(\"articleoutput.csv\") \n",
        "header = [\"article_no\"]\n",
        "df1.to_csv('articleno.csv', columns = header)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiF50MalJmD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import itertools\n",
        "contents = []\n",
        "with open('articleno.csv','r') as csvf:\n",
        "    urls = csv.reader(csvf)\n",
        "    next(urls, None)\n",
        "    contents = [row[1] for row in itertools.islice(urls,768)] \n",
        "string = 'https://api.semanticscholar.org/v1/paper/'\n",
        "my_new_list = [string+x for x in contents]\n",
        "with open(\"Article_URLs.csv\",\"w\") as f:\n",
        "    writer = csv.writer(f,delimiter=\"\\n\")\n",
        "    writer.writerow(['ArticleURL'])\n",
        "    writer.writerow(my_new_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsTKtQwTJ0OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import URLError, HTTPError\n",
        "import time\n",
        "countUp = 0\n",
        "headers = {}\n",
        "headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17'\n",
        "for j in my_new_list:\n",
        " time.sleep(2)\n",
        " try:\n",
        "     req = urllib.request.Request(j,headers=headers)\n",
        "     response = urllib.request.urlopen(req)\n",
        "     res=response.read().decode('utf8')\n",
        "     time.sleep(0.1)\n",
        "     print(\"Here\")\n",
        "     with open ('/content/jsonfiles/Article' + str(countUp) + '.json', 'w') as g:\n",
        "          g.write(res)\n",
        "     countUp += 1\n",
        " except HTTPError as e:\n",
        "    print('The server couldn\\'t fulfill the request.')\n",
        "    print('Error code: ', e.code)\n",
        "    time.sleep(30) \n",
        " except URLError as e:\n",
        "    print('We failed to reach a server.')\n",
        "    print('Reason: ', e.reason)\n",
        "    time.sleep(30)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeFiEnAJqOik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "#For the folder you have to zip it first and can only download later on\n",
        "!zip -r jsonfiles.zip /content/jsonfiles\n",
        "#Download files\n",
        "files.download('jsonfiles.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u03IlkWDLukt",
        "colab_type": "code",
        "outputId": "0719b4b4-34fd-4843-c031-c0e6316140a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install textblob\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
        "from textblob import Word\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "st=PorterStemmer()\n",
        "stop=stopwords.words('english')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "#table 1\n",
        "import json\n",
        "import pandas\n",
        "from pandas import DataFrame\n",
        "Venuelist = []\n",
        "Titlelist = []\n",
        "Yearlist = []\n",
        "Abstractlist = []\n",
        "Doilist = []\n",
        "FieldsOfStudylist = []\n",
        "Topiclist = []\n",
        "urllist = []\n",
        "influentialCitationCountlist = []\n",
        "articleidlist = []\n",
        "for i in range(968):\n",
        "  f = open('/content/jsonfiles/Article' + str(i) + '.json')\n",
        "  data = json.load(f)\n",
        "  string = 'https://doi.org/'\n",
        "  articleidlist = [string+x for x in Doilist]\n",
        "  venue = data['venue']\n",
        "  Venuelist.append(venue)\n",
        "  title = data['title']\n",
        "  Titlelist.append(title)\n",
        "  year = data['year']\n",
        "  Yearlist.append(year)\n",
        "  abstract = data['abstract']\n",
        "  Abstractlist.append(abstract)\n",
        "  doi = data['doi']\n",
        "  Doilist.append(doi)\n",
        "  fieldsOfStudy = data['fieldsOfStudy']\n",
        "  FieldsOfStudylist.append(fieldsOfStudy)\n",
        "  influentialCitationCount = data['influentialCitationCount']\n",
        "  influentialCitationCountlist.append(influentialCitationCount)\n",
        "  for value in data['topics']:\n",
        "    topic = value['topic']\n",
        "    Topiclist.append(topic)\n",
        "  url = data['url']\n",
        "  urllist.append(url)   \n",
        "f.close()\n",
        "#print(Topiclist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLPN58NCE1rR",
        "colab_type": "code",
        "outputId": "bd58d634-7ab2-4958-ec92-69652c0657e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import string\n",
        "\n",
        "# Select all the files in your directory\n",
        "fields = [\"article_id\",\"pdf_link\",\"total_citation\",\"total_download\",\"pdf_link\",\"article_no\"]\n",
        "dfarticle = pd.read_csv(\"articleoutput.csv\", usecols=fields)\n",
        "doilist = dfarticle['article_no'].values.tolist()\n",
        "articleidlist = dfarticle['article_id'].values.tolist()\n",
        "totalcitationlist = dfarticle['total_citation'].values.tolist()\n",
        "totaldownloadlist = dfarticle['total_download'].values.tolist()\n",
        "pdflinklist = dfarticle['pdf_link'].values.tolist()\n",
        "a = {'Article_id' : articleidlist ,'Venue' : Venuelist ,'Title' : Titlelist ,'Year' :Yearlist, 'Abstract': Abstractlist,\n",
        "     'Doi' : doilist,'fieldsOfStudy' : FieldsOfStudylist,'Downloadurl' : pdflinklist,\n",
        "     'TotalCitationCount' : totalcitationlist, 'TotalDownloadCount' : totaldownloadlist, 'Influentialcitationcount' : influentialCitationCountlist}\n",
        "df = pd.DataFrame.from_dict(a, orient='index')\n",
        "#df['fieldsOfStudy'].str.strip('[]').astype(int)\n",
        "df1 = df.transpose()\n",
        "#df1['fieldsOfStudy'] = df1['fieldsOfStudy'].str.strip('[]')\n",
        "df1[\"Abstract\"]=df1[\"Abstract\"].str.lower() \n",
        "df1['Abstract'] = df1['Abstract'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
        "df1[\"Abstract\"]=df1['Abstract'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "df1['fieldsOfStudy'] = df1['fieldsOfStudy'].apply(str)\n",
        "df1['fieldsOfStudy'] = df1['fieldsOfStudy'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "df1['fieldsOfStudy']\n",
        "df1.to_csv('/content/jsonfiles/table1.csv', columns = a)\n",
        "print(df1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Article_id  ... Influentialcitationcount\n",
            "0    https://doi.org/10.1145/511285.511286  ...                        0\n",
            "1    https://doi.org/10.1145/511285.511288  ...                        0\n",
            "2    https://doi.org/10.1145/511285.511289  ...                        0\n",
            "3    https://doi.org/10.1145/511285.511290  ...                        0\n",
            "4    https://doi.org/10.1145/511285.511292  ...                        0\n",
            "..                                     ...  ...                      ...\n",
            "970  https://doi.org/10.1145/345508.345671  ...                     None\n",
            "971  https://doi.org/10.1145/345508.345672  ...                     None\n",
            "972  https://doi.org/10.1145/345508.345673  ...                     None\n",
            "973  https://doi.org/10.1145/345508.345674  ...                     None\n",
            "974  https://doi.org/10.1145/345508.345675  ...                     None\n",
            "\n",
            "[975 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xW7sl5fSVEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#table 2\n",
        "import json\n",
        "import pandas\n",
        "from pandas import DataFrame\n",
        "authorIdlist = []\n",
        "authorname = []\n",
        "authorurl = []\n",
        "doilist = []\n",
        "#authorrank = []\n",
        "#authorinstitution = []\n",
        "#authorPublication = []\n",
        "for i in range(968):\n",
        "  f = open('/content/jsonfiles/Article' + str(i) + '.json')\n",
        "  data = json.load(f)\n",
        "  string = 'https://doi.org/'\n",
        "  articleidlist = [string+x for x in Doilist]\n",
        "  doi = data['doi']\n",
        "  Doilist.append(doi)\n",
        "  for value in data['authors']:\n",
        "    authorId = value['authorId']\n",
        "    authorIdlist.append(authorId) \n",
        "  for value in data['authors']:\n",
        "    name = value['name']\n",
        "    authorname.append(name) \n",
        "  for value in data['authors']:\n",
        "    url = value['url']\n",
        "    authorurl.append(url)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgbykSVgSgrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "# Select all the files in your directory\n",
        "a = {'authorId' : authorIdlist ,'name' : authorname ,'url' : authorurl }\n",
        "df = pd.DataFrame.from_dict(a, orient='index')\n",
        "df1 = df.transpose()\n",
        "df1.to_csv('/content/jsonfiles/table2.csv', columns = a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li2sigzGRCAw",
        "colab_type": "code",
        "outputId": "8055b05a-e590-439c-e8ea-8ddf148e1d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#table 3\n",
        "import json\n",
        "import pandas\n",
        "from pandas import DataFrame\n",
        "citingpaperId = []\n",
        "citingdoi = []\n",
        "citingtitle = []\n",
        "citingvenue = []\n",
        "citingyear = []\n",
        "citingintent = []\n",
        "citinginfluential = []\n",
        "for i in range(968):\n",
        "  f = open('/content/jsonfiles/Article' + str(i) + '.json')\n",
        "  data = json.load(f)\n",
        "  for value in data['citations']:\n",
        "    paperId = value['paperId']\n",
        "    citingpaperId.append(paperId)\n",
        "    #print(paperId)\n",
        "    doi = value['doi']\n",
        "    citingdoi.append(doi)\n",
        "    #print(doi)\n",
        "    title = value['title']\n",
        "    citingtitle.append(title)\n",
        "    #print(title)\n",
        "    venue = value['venue']\n",
        "    citingvenue.append(venue)\n",
        "    #print(venue)\n",
        "    year = value['year']\n",
        "    citingyear.append(year)\n",
        "    #print(year)\n",
        "    intent = value['intent']\n",
        "    citingintent.append(intent)\n",
        "    #print(intent)\n",
        "    isInfluential = value['isInfluential']\n",
        "    citinginfluential.append(isInfluential) \n",
        "    #print(isInfluential)\n",
        "a = {'paperId' : citingpaperId ,'doi' : citingdoi ,'title' : citingtitle ,\n",
        "     'venue' :citingvenue, 'year': citingyear,\n",
        "     'intent' : citingintent,'isInfluential' : citinginfluential}\n",
        "df = pd.DataFrame.from_dict(a, orient='index')\n",
        "df1 = df.transpose()\n",
        "df1['intent'] = df1['intent'].apply(lambda x : ' '.join(map(str, x)))\n",
        "df1.to_csv('/content/jsonfiles/table3.csv', columns = a)\n",
        "print(df1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        paperId  ... isInfluential\n",
            "0      8113edc6c95508bc7f9ae624903f8f4c98d3395b  ...         False\n",
            "1      819c14aeb7fbd7819baa58f038142db1f0cfc351  ...         False\n",
            "2      28dd43a10b78cc6297081fb7b9be86e114894391  ...         False\n",
            "3      24f73ab2828f9aecbc079a9d5f5028c392eaa5b0  ...         False\n",
            "4      393a9de965783f2c0f42b82db47321df10402472  ...         False\n",
            "...                                         ...  ...           ...\n",
            "65632  e85206cb8c17461f8f823972a44a33b2eaed1ddb  ...         False\n",
            "65633  4665b979d409e9878404ead82e87d787cbca270f  ...         False\n",
            "65634  c022253b7988d517a53f48edf5867b3b5557271d  ...         False\n",
            "65635  d4ce5e9394ecd2cb3e64bb952885a236e99f1fc5  ...         False\n",
            "65636  04ab5ed3635a75bfd6b0c95598dbf38a1d4f63e8  ...         False\n",
            "\n",
            "[65637 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0ZkxpshyrM",
        "colab_type": "code",
        "outputId": "62c15a6f-4b0c-4373-a8db-4de877ed7fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#table 4\n",
        "import re\n",
        "referencepaperidlist = []\n",
        "Referencepaperdoilist = []\n",
        "Referencepapertitlelist = []\n",
        "Referencepapervenuelist = []\n",
        "Referencepaperyearlist = []\n",
        "Isinfluentiallist = [] \n",
        "Intentlist = []\n",
        "for i in range(968):\n",
        "  f = open('/content/jsonfiles/Article' + str(i) + '.json')\n",
        "  data = json.load(f)\n",
        "  for value in data['references']:\n",
        "    referencepaperid = value['paperId']\n",
        "    referencepaperidlist.append(referencepaperid)\n",
        "    referencepaperdoi = value['doi']\n",
        "    Referencepaperdoilist.append(referencepaperdoi)\n",
        "    Referencepapertitle = value['title']\n",
        "    Referencepapertitlelist.append(Referencepapertitle)\n",
        "    Referencepapervenue = value['venue']\n",
        "    Referencepapervenuelist.append(Referencepapervenue)\n",
        "    Referencepaperyear = value['year']\n",
        "    Referencepaperyearlist.append(Referencepaperyear)\n",
        "    Intent = value['intent']\n",
        "    Intentlist.append(Intent)\n",
        "    Isinfluential = value['isInfluential']\n",
        "    Isinfluentiallist.append(Isinfluential)\n",
        "a = {'Reference_paper_id' : referencepaperidlist ,'Reference _paper_doi' : Referencepaperdoilist ,'Reference _paper_title' : Referencepapertitlelist ,\n",
        "     'Reference _paper_venue' :Referencepapervenuelist, 'Reference _paper_year': Referencepaperyearlist,\n",
        "     'Intent' : Intentlist,'Is_influential' : Isinfluentiallist}\n",
        "df = pd.DataFrame.from_dict(a, orient='index')\n",
        "df1 = df.transpose()\n",
        "df1['Intent'] = df1['Intent'].apply(lambda x : ' '.join(map(str, x)))\n",
        "df1.to_csv('/content/jsonfiles/table4.csv', columns = a)\n",
        "print(df1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            Reference_paper_id  ... Is_influential\n",
            "0     cb93b7894a19780851dcaf0559a8c4f9ac1a7694  ...          False\n",
            "1     6f7949a0301963ca49d88c5c96b375ded713a31b  ...          False\n",
            "2     dccea747182423d212741a6eecabf4d2024efb52  ...          False\n",
            "3     a76e8341a099a3ab447ee16aafcd24213cb0dd18  ...          False\n",
            "4     848dc213c8e0d1d33dd57e91b713e1dce1a6ef1e  ...          False\n",
            "...                                        ...  ...            ...\n",
            "8515  8b414a17fe8142a9ff5f5af6ba63564652e7534f  ...          False\n",
            "8516  9f4e1ce21458d3cd8b74c0a19dea77db3bc0575f  ...          False\n",
            "8517  53d61dad3b913c7c8ac602ed82fb5445ca506648  ...          False\n",
            "8518  e5305866d701a2c102c5f81fbbf48bf6ac29f252  ...          False\n",
            "8519  b3294141d08b8d57e1e2d87cee1d43f6e4ef12ac  ...          False\n",
            "\n",
            "[8520 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}